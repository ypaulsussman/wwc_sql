- Review remaining fields with significantly-repeating values; extract to new tables as reasonable

- Export db as 'final' normalized setup (both with pg_dump and pg_dump -a, in case you can use the latter as a seeds file)

- Create Rails API app
- Add AR models as scaffolds
  - (Probably?) delete individual-model migrations
  - Replace w/ initial 'setup and seed from .sql file' migration
- Use migrations for:
  - Ruby script to replace states w/ many-many join table
    - Drop regions (each between 150 and 300 records; not very comprehensive)
    - Maybe same for school-types...
  - Repeat extraction-process with any sets of (internally mutually-exclusive) boolean fields in `studies`
  - Add scraper script for FTS `descriptions` field on `interventions` table
    - Use Intervention_Page_URL field from InterventionReport
- Test controller endpoints w/ Postman

- Create single-page React app

- Add user-auth/JWT-protection
  - Save each search
  - Allow logged-in users to save searches (i.e. associate a search with their email)




---------///---------///---------///---------///---------///---------///



When deploying: possible to put entire db in-cache (via setting `shared_buffers` to greater than size of db)?



---------///---------///---------///---------///---------///---------///

## Models

Protocol
has_many :studies, :reports

Intervention
has_many :reports
has_many :studies 
has_many :findings, through: :studies

Finding
belongs_to :intervention

Report
belongs_to :intervention

Study 
belongs_to :intervention
has_many :findings


OutcomeDomain
has_many :findings
has_many :reports
